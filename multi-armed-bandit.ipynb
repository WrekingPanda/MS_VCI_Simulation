{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c23479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import traci\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1766c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# LOAD DATA & CONFIG\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "SUMO_BINARY = r\"C:\\Program Files (x86)\\Eclipse\\Sumo\\bin\\sumo.exe\"          # or \"sumo-gui\"\n",
    "SUMO_CFG = r\"C:\\Users\\Paulo Alexandre\\Documents\\PauloAlexandre\\Ensino_Superior\\MIA\\1_Ano\\1_Semestre\\MS\\Projeto\\MS_VCI_Simulation\\simulation\\vci.sumocfg\"  # must reference your .net.xml\n",
    "\n",
    "# Possible origins\n",
    "START_EDGES_C = [\"1019723\",\"1019718\",\"1063513\",\"1062943\",\"1020382\",\"2842002\",\"1020167\",\"1020160\",\"2842000\",\"1516937\",\"1016643\",\"1020050\",\"1020045\",\"1019568\",\"1210462\",\"1582715\",\"1405109\",\"1302643\",\"1038024\",\"1215193\",\"2016241\",\"1810069\",\"1204005\",\"1401473\",\"1204022\",\"1189928\"]\n",
    "START_EDGES_D = [\"1189910\",\"1401479\",\"1175990\",\"1111269.111\",\"1111267\",\"1215241\",\"1181539\",\"1111242\",\"1216119\",\"1122615\",\"1016648\",\"1188031\",\"1255432\",\"1020165\",\"1768757\",\"1949246\",\"1306152\",\"1062246\",\"1122691\",\"1019722\",\"1019716\",\"1401214\"]\n",
    "# Possible destinations\n",
    "END_EDGES_C = [\"1019719\",\"1122692\",\"1063262\",\"1047385\",\"1076349\",\"1016658\",\"1020171\",\"1020157\",\"1888721\",\"1888720\",\"2020471\",\"1016644\",\"1020046\",\"1020029\",\"1019569\",\"1210226\",\"1111488\",\"1036157\",\"1016681\",\"1215220\",\"1935065\",\"1175980\",\"1401472\",\"1189936\",\"1210069\"]\n",
    "END_EDGES_D = [\"1401537\",\"1189937\",\"1203952\",\"1810067\",\"1111269\",\"1188014\",\"1215352\",\"1181481\",\"1111240\",\"1214240\",\"1019567\",\"1020004\",\"2006681\",\"1019667\",\"1020161\",\"1020174\",\"1016657\",\"1054906\",\"1047469\",\"1062317\",\"1063338\",\"1019717\",\"1051044\",\"1972190\"]\n",
    "\n",
    "# Load preprocessed data\n",
    "train_df = pd.read_csv(\"./Dataset/simple_train.csv\", parse_dates=[\"AGG_PERIOD_START\"])\n",
    "test_df = pd.read_csv(\"./Dataset/simple_test.csv\", parse_dates=[\"AGG_PERIOD_START\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c791c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_half_arm(df):\n",
    "    \"\"\"\n",
    "    Ensure df['half_arm'] is a tuple: (half_time_bin, EQUIPMENTID, LANE_BUNDLE_DIRECTION)\n",
    "    \"\"\"\n",
    "    if isinstance(df[\"half_arm\"].iloc[0], tuple):\n",
    "        return df\n",
    "\n",
    "    # Example if it's a string like \"(bin, sensor, 'C')\": parse it\n",
    "    def parse_arm(s):\n",
    "        # Adjust this parser depending on your actual format\n",
    "        # Example: \"(10, 121726, 'C')\" -> (10, 121726, 'C')\n",
    "        return eval(s)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"half_arm\"] = df[\"half_arm\"].apply(parse_arm)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d4e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ensure_half_arm(train_df)\n",
    "test_df = ensure_half_arm(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa2d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(df):\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = df[\"AGG_PERIOD_START\"].dt.date\n",
    "    return df\n",
    "\n",
    "def get_real_counts_for_day(df_day):\n",
    "    \"\"\"\n",
    "    Aggregate TOTAL_VOLUME per arm for one day.\n",
    "    Returns {arm: volume}.\n",
    "    \"\"\"\n",
    "    g = df_day.groupby(\"half_arm\")[\"TOTAL_VOLUME\"].sum()\n",
    "    return g.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4766c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sensor_edge_mapping():\n",
    "    \"\"\"\n",
    "    Build a mapping: (sensor_id, dir) -> (start_edge, end_edge).\n",
    "\n",
    "    TODO: Replace this heuristic with your actual mapping, based on\n",
    "          how each AEDL sensor corresponds to SUMO edges and direction.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    # Example: round-robin assignment for demo\n",
    "    # WARNING: replace with real mapping!\n",
    "    for i, s in enumerate(sorted(train_df[\"EQUIPMENTID\"].unique())):\n",
    "        start_c = START_EDGES_C[i % len(START_EDGES_C)]\n",
    "        end_c   = END_EDGES_C[i % len(END_EDGES_C)]\n",
    "        mapping[(s, \"C\")] = (start_c, end_c)\n",
    "\n",
    "    for i, s in enumerate(sorted(train_df[\"EQUIPMENTID\"].unique())):\n",
    "        start_d = START_EDGES_D[i % len(START_EDGES_D)]\n",
    "        end_d   = END_EDGES_D[i % len(END_EDGES_D)]\n",
    "        mapping[(s, \"D\")] = (start_d, end_d)\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7caeef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianThompsonBandit:\n",
    "    \"\"\"\n",
    "    Simple independent Gaussian Thompson Sampling per arm.\n",
    "    Reward = -loss; here we will approximate per-arm reward using\n",
    "    negative squared error between sim and real volume.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, arms, init_mean=20.0, init_var=100.0, obs_noise_var=100.0):\n",
    "        \"\"\"\n",
    "        arms: iterable of arm IDs (e.g., tuples (half_bin, sensor, dir))\n",
    "        init_mean: prior mean for flow\n",
    "        init_var:  prior variance\n",
    "        obs_noise_var: assumed observation noise variance\n",
    "        \"\"\"\n",
    "        self.arms = list(arms)\n",
    "        self.obs_noise_var = obs_noise_var\n",
    "        self.means = {a: init_mean for a in self.arms}\n",
    "        self.vars  = {a: init_var  for a in self.arms}\n",
    "\n",
    "    def sample_flows(self):\n",
    "        \"\"\"\n",
    "        Sample a flow (mean vehicles) for each arm.\n",
    "        Returns {arm: flow_estimate}\n",
    "        \"\"\"\n",
    "        flows = {}\n",
    "        for a in self.arms:\n",
    "            mu = self.means[a]\n",
    "            var = self.vars[a]\n",
    "            flows[a] = max(np.random.normal(mu, np.sqrt(var)), 0.0)\n",
    "        return flows\n",
    "\n",
    "    def update(self, real_counts, sim_counts, reward=None):\n",
    "        \"\"\"\n",
    "        Update posterior given real and simulated counts for each arm.\n",
    "        We treat the real volume as (noisy) observation of the mean flow.\n",
    "\n",
    "        real_counts: {arm: real_volume}\n",
    "        sim_counts:  {arm: sim_volume}\n",
    "        \"\"\"\n",
    "        # Pick one arm to monitor (Optional)\n",
    "        debug_arm = next(iter(self.arms)) if self.arms else None\n",
    "        before = (self.means.get(debug_arm), self.vars.get(debug_arm)) if debug_arm else None\n",
    "\n",
    "        # Here we only use real_counts to update the prior,\n",
    "        # but you can also use the error sim - real in a more complex way.\n",
    "        for a, y in real_counts.items():\n",
    "            mu_prior = self.means[a]\n",
    "            var_prior = self.vars[a]\n",
    "            var_noise = self.obs_noise_var\n",
    "\n",
    "            # Bayesian update for normal-normal model\n",
    "            var_post = 1.0 / (1.0 / var_prior + 1.0 / var_noise)\n",
    "            mu_post = var_post * (mu_prior / var_prior + y / var_noise)\n",
    "\n",
    "            self.means[a] = mu_post\n",
    "            self.vars[a]  = var_post\n",
    "\n",
    "        if debug_arm is not None:\n",
    "            after = (self.means[debug_arm], self.vars[debug_arm])\n",
    "            print(f\"[BANDIT] Arm {debug_arm} mean/var before {before} -> after {after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c297ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trips_for_day(flow_estimates, sensor_edge_map, time_bins_per_arm):\n",
    "    \"\"\"\n",
    "    flow_estimates: {arm: flow_value} (arm = (half_bin, sensor, dir))\n",
    "    sensor_edge_map: {(sensor, dir): (start_edge, end_edge)}\n",
    "    time_bins_per_arm: {arm: (start_sec, end_sec)} for that half_bin\n",
    "\n",
    "    Returns list of trips:\n",
    "        [(veh_id, depart_time, start_edge, end_edge, arm), ...]\n",
    "    \"\"\"\n",
    "    trips = []\n",
    "    v_idx = 0\n",
    "    for arm, flow_val in flow_estimates.items():\n",
    "        half_bin, sensor_id, direction = arm\n",
    "\n",
    "        # integer number of vehicles\n",
    "        n = int(round(max(flow_val, 0.0)))\n",
    "\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        key = (sensor_id, direction)\n",
    "        if key not in sensor_edge_map:\n",
    "            continue  # no mapping, skip\n",
    "\n",
    "        start_edge, end_edge = sensor_edge_map[key]\n",
    "\n",
    "        # time interval (in seconds) for this half-hour bin within the day\n",
    "        t0, t1 = time_bins_per_arm[arm]\n",
    "\n",
    "        for _ in range(n):\n",
    "            depart = random.uniform(t0, t1)\n",
    "            veh_id = f\"veh_{v_idx}\"\n",
    "            trips.append((veh_id, depart, start_edge, end_edge, arm))\n",
    "            v_idx += 1\n",
    "\n",
    "    print(f\"[DEBUG] build_trips_for_day: {len(trips)} trips total.\")\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea7d58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_time_bins_for_half_hour():\n",
    "    \"\"\"\n",
    "    half_bin 0..47 -> (start_sec, end_sec) within a single day.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for hb in range(48):\n",
    "        start_min = hb * 30\n",
    "        end_min   = start_min + 30\n",
    "        mapping[hb] = (start_min * 60, end_min * 60)\n",
    "    return mapping\n",
    "\n",
    "def build_time_bins_per_arm(arms):\n",
    "    \"\"\"\n",
    "    arms: iterable of (half_bin, sensor, dir)\n",
    "    returns {arm: (start_sec, end_sec)}\n",
    "    \"\"\"\n",
    "    half_bin_map = build_time_bins_for_half_hour()\n",
    "    return {a: half_bin_map[a[0]] for a in arms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61119e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps the real sensors to the SUMO induction loop detectors introduced by us\n",
    "sensor_id_to_detectors = {121726: [\"121726_0\", \"121726_1\", \"121726_2\"],\n",
    "                          121727: [\"121727_0\", \"121727_1\", \"121727_2\"],\n",
    "                          121731: [\"121731_0\", \"121731_1\", \"121731_2\", \"121731_3\"],\n",
    "                          121732: [\"121732_0\", \"121732_1\", \"121732_2\", \"121732_3\"],\n",
    "                          121733: [\"121733_0\", \"121733_1\", \"121733_2\"],\n",
    "                          121734: [\"121734_0\", \"121734_1\", \"121734_2\", \"121734_3\"],\n",
    "                          121735: [\"121735_0\", \"121735_1\", \"121735_2\"],\n",
    "                          121736: [\"121736_0\", \"121736_1\", \"121736_2\"],\n",
    "                          121741: [\"121741_0\", \"121741_1\", \"121741_2\"],\n",
    "                          121742: [\"121742_0\", \"121742_1\", \"121742_2\"],\n",
    "                          121754: [\"121754_0\", \"121754_1\"],\n",
    "                          121755: [\"121755_0\", \"121755_1\"],\n",
    "                          121756: [\"121756_0\", \"121756_1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dcb6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the real sensors to the direction of the road they monitor ('C' or 'D')\n",
    "sensor_direction = {121726: 'D',\n",
    "                    121727: 'D',\n",
    "                    121731: 'C',\n",
    "                    121732: 'C',\n",
    "                    121733: 'C',\n",
    "                    121734: 'C',\n",
    "                    121735: 'C',\n",
    "                    121736: 'C',\n",
    "                    121741: 'C',\n",
    "                    121742: 'C',\n",
    "                    121754: 'D',\n",
    "                    121755: 'C',\n",
    "                    121756: 'C'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79fbf378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sumo_episode(trips, sensor_edge_map, sensor_id_to_detectors):\n",
    "    \"\"\"\n",
    "    trips: [(veh_id, depart, start_edge, end_edge, arm), ...]\n",
    "    sensor_edge_map: {(sensor, dir): (start_edge, end_edge)}\n",
    "    sensor_id_to_detectors: {sensor_id: [list_of_sumo_detector_ids]} \n",
    "                            Example: {121726: [\"det_121726_0\", \"det_121726_1\"]}\n",
    "\n",
    "    Returns sim_counts: {arm: simulated_volume}\n",
    "    \"\"\"\n",
    "    print(f\"[SUMO] Starting episode with {len(trips)} trips.\")\n",
    "    \n",
    "    # Start SUMO\n",
    "    traci.start([SUMO_BINARY, \"-c\", SUMO_CFG])\n",
    "\n",
    "    # Initialize counts for all possible arms to 0\n",
    "    sim_counts = defaultdict(int)\n",
    "\n",
    "    try:\n",
    "        # 1) Add all routes and vehicles (Batch add to be faster)\n",
    "        for veh_id, depart, start_edge, end_edge, arm in trips:\n",
    "            route_id = f\"r_{veh_id}\"\n",
    "            traci.route.add(route_id, [start_edge, end_edge])\n",
    "            traci.vehicle.add(\n",
    "                vehID=veh_id,\n",
    "                routeID=route_id,\n",
    "                typeID=\"car\",\n",
    "                depart=str(depart)\n",
    "            )\n",
    "\n",
    "        # 2) Simulation Loop with Sensor Reading\n",
    "        # Precompute once, before the while-loop\n",
    "        unique_sensors = {arm[1] for _, _, _, _, arm in trips}\n",
    "        \n",
    "        step = 0\n",
    "        while traci.simulation.getMinExpectedNumber() > 0:\n",
    "            traci.simulationStep()\n",
    "            \n",
    "            # A. Get current simulation time\n",
    "            current_time = traci.simulation.getTime()\n",
    "            \n",
    "            if step % 600 == 0:\n",
    "                print(f\"[SUMO] step={step}, t={current_time}, \"f\"remaining={traci.simulation.getMinExpectedNumber()}\")\n",
    "\n",
    "            # B. Determine which \"Half-Hour Bin\" we are in (0 to 47)\n",
    "            # 1800 seconds = 30 minutes\n",
    "            current_half_bin = int(current_time // 1800)\n",
    "            \n",
    "            # C. Loop through your sensors and get counts\n",
    "            # We iterate through the unique sensors in your map\n",
    "            # Note: You might want to optimize this loop if you have thousands of sensors\n",
    "            # unique_sensors = set(s_id for (_, s_id, _) in trips) # Or pass a list of active sensors\n",
    "            \n",
    "            for sensor_id in unique_sensors:\n",
    "                detector_ids = sensor_id_to_detectors.get(sensor_id, [])\n",
    "                step_count = 0\n",
    "                for det_id in detector_ids:\n",
    "                    step_count += traci.inductionloop.getLastStepVehicleNumber(det_id)\n",
    "\n",
    "                if step_count > 0:\n",
    "                    arm_key = (current_half_bin, sensor_id, sensor_direction[sensor_id])\n",
    "                    sim_counts[arm_key] += step_count\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        print(f\"[SUMO] Episode finished at step {step}.\")\n",
    "        print(f\"[SUMO] Simulated counts (first 5): {list(sim_counts.items())[:5]}\")\n",
    "\n",
    "    finally:\n",
    "        traci.close()\n",
    "        print(\"[SUMO] Connection closed.\")\n",
    "\n",
    "    return dict(sim_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc25e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(sim_counts, real_counts, loss_type=\"l1\"):\n",
    "    \"\"\"\n",
    "    sim_counts:  {arm: simulated_volume}\n",
    "    real_counts: {arm: real_volume}\n",
    "    loss_type:   \"l1\" (absolute error) or \"l2\" (squared error)\n",
    "\n",
    "    Returns a scalar loss (higher = worse).\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "\n",
    "    # Union of arms present in either dict\n",
    "    all_arms = set(real_counts.keys()) | set(sim_counts.keys())\n",
    "\n",
    "    for arm in all_arms:\n",
    "        y_real = real_counts.get(arm, 0.0)\n",
    "        y_sim  = sim_counts.get(arm, 0.0)\n",
    "        diff = y_sim - y_real\n",
    "\n",
    "        if loss_type == \"l2\":\n",
    "            loss += diff ** 2\n",
    "        else:  # \"l1\"\n",
    "            loss += abs(diff)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75704769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bandit_with_sumo(train_df, num_episodes=None):\n",
    "    # Ensure half_arm is a tuple\n",
    "    train_df = ensure_half_arm(train_df)\n",
    "    train_df = add_date(train_df)\n",
    "\n",
    "    # Arms from training data\n",
    "    arms = sorted(train_df[\"half_arm\"].unique())\n",
    "    bandit = GaussianThompsonBandit(arms)\n",
    "\n",
    "    # Mapping from (sensor, dir) to (start_edge, end_edge)\n",
    "    sensor_edge_map = build_sensor_edge_mapping()\n",
    "    \n",
    "    # Maps the real sensors to the SUMO induction loop detectors introduced by us\n",
    "    sensor_id_to_detectors = {121726: [\"121726_0\", \"121726_1\", \"121726_2\"],\n",
    "                            121727: [\"121727_0\", \"121727_1\", \"121727_2\"],\n",
    "                            121731: [\"121731_0\", \"121731_1\", \"121731_2\", \"121731_3\"],\n",
    "                            121732: [\"121732_0\", \"121732_1\", \"121732_2\", \"121732_3\"],\n",
    "                            121733: [\"121733_0\", \"121733_1\", \"121733_2\"],\n",
    "                            121734: [\"121734_0\", \"121734_1\", \"121734_2\", \"121734_3\"],\n",
    "                            121735: [\"121735_0\", \"121735_1\", \"121735_2\"],\n",
    "                            121736: [\"121736_0\", \"121736_1\", \"121736_2\"],\n",
    "                            121741: [\"121741_0\", \"121741_1\", \"121741_2\"],\n",
    "                            121742: [\"121742_0\", \"121742_1\", \"121742_2\"],\n",
    "                            121754: [\"121754_0\", \"121754_1\"],\n",
    "                            121755: [\"121755_0\", \"121755_1\"],\n",
    "                            121756: [\"121756_0\", \"121756_1\"]}\n",
    "\n",
    "    # Time-bin mapping\n",
    "    time_bins_per_arm = build_time_bins_per_arm(arms)\n",
    "\n",
    "    # Group by day\n",
    "    grouped = train_df.groupby(\"date\")\n",
    "    days = list(grouped.groups.keys())\n",
    "    if num_episodes is not None:\n",
    "        days = days[:num_episodes]\n",
    "\n",
    "    print(f\"[INFO] Training on {len(days)} days, {len(arms)} arms.\")\n",
    "\n",
    "    for day_idx, day in enumerate(days, start=1):\n",
    "        df_day = grouped.get_group(day)\n",
    "        print(f\"\\n[DAY {day_idx}/{len(days)}] {day}\")\n",
    "\n",
    "        # Real counts per arm for this day\n",
    "        real_counts = get_real_counts_for_day(df_day)\n",
    "        print(f\"[DAY {day}] unique arms today: {len(real_counts)}\")\n",
    "\n",
    "        # 1) Bandit samples flow estimates per arm\n",
    "        flow_estimates = bandit.sample_flows()\n",
    "        print(f\"[DAY {day}] sampled flows (first 5): {list(flow_estimates.items())[:5]}\")\n",
    "\n",
    "        # 2) Build trips for this day from flow estimates\n",
    "        trips = build_trips_for_day(flow_estimates, sensor_edge_map, time_bins_per_arm)\n",
    "        print(f\"[DAY {day}] generated {len(trips)} trips.\")\n",
    "\n",
    "        # 3) Run SUMO and get simulated counts per arm\n",
    "        sim_counts = run_sumo_episode(trips, sensor_edge_map, sensor_id_to_detectors)\n",
    "        \n",
    "        # 4) Compute simple loss for logging\n",
    "        loss = compute_loss(sim_counts, real_counts, loss_type=\"l1\")\n",
    "        reward = -loss\n",
    "        print(f\"[DAY {day}] Loss: {loss:.2f} | Reward: {reward:.2f}\")\n",
    "\n",
    "        # 5) Update bandit with real and simulated counts\n",
    "        bandit.update(real_counts, sim_counts, reward)\n",
    "        print(f\"[DAY {day}] bandit updated.\")\n",
    "\n",
    "    return bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training on 2 days, 1248 arms.\n",
      "\n",
      "[DAY 1/2] 2013-03-01\n",
      "[DAY 2013-03-01] unique arms today: 1056\n",
      "[DAY 2013-03-01] sampled flows (first 5): [((0, 121726, 'C'), 0.0), ((0, 121726, 'D'), 19.743793811589157), ((0, 121727, 'C'), 42.767993855981786), ((0, 121727, 'D'), 22.248388388263553), ((0, 121731, 'C'), 9.033689158985666)]\n",
      "[DEBUG] build_trips_for_day: 25314 trips total.\n",
      "[DAY 2013-03-01] generated 25314 trips.\n",
      "[SUMO] Starting episode with 25314 trips.\n",
      "[SUMO] step=0, t=1.0, remaining=25318\n",
      "[SUMO] step=600, t=601.0, remaining=25715\n",
      "[SUMO] step=1200, t=1201.0, remaining=25295\n",
      "[SUMO] step=1800, t=1801.0, remaining=25052\n",
      "[SUMO] step=2400, t=2401.0, remaining=24913\n",
      "[SUMO] step=3000, t=3001.0, remaining=24747\n",
      "[SUMO] step=3600, t=3601.0, remaining=24567\n",
      "[SUMO] step=4200, t=4201.0, remaining=24396\n",
      "[SUMO] step=4800, t=4801.0, remaining=24209\n",
      "[SUMO] step=5400, t=5401.0, remaining=24014\n",
      "[SUMO] step=6000, t=6001.0, remaining=23832\n",
      "[SUMO] step=6600, t=6601.0, remaining=23628\n",
      "[SUMO] step=7200, t=7201.0, remaining=23435\n",
      "[SUMO] step=7800, t=7801.0, remaining=23283\n",
      "[SUMO] step=8400, t=8401.0, remaining=23131\n",
      "[SUMO] step=9000, t=9001.0, remaining=22968\n",
      "[SUMO] step=9600, t=9601.0, remaining=22795\n",
      "[SUMO] step=10200, t=10201.0, remaining=22596\n",
      "[SUMO] step=10800, t=10801.0, remaining=22402\n",
      "[SUMO] step=11400, t=11401.0, remaining=22195\n",
      "[SUMO] step=12000, t=12001.0, remaining=22008\n",
      "[SUMO] step=12600, t=12601.0, remaining=21823\n",
      "[SUMO] step=13200, t=13201.0, remaining=21659\n",
      "[SUMO] step=13800, t=13801.0, remaining=21500\n",
      "[SUMO] step=14400, t=14401.0, remaining=21327\n",
      "[SUMO] step=15000, t=15001.0, remaining=21153\n"
     ]
    }
   ],
   "source": [
    "train_bandit_with_sumo(train_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55776812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
